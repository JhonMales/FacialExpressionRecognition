# -*- coding: utf-8 -*-
"""Reto Final

Automatically generated by Colaboratory.

**Jhon Males 20191020144**
"""

from google.colab import drive
drive.mount('/content/gdrive')

import tensorflow as tf
import os 
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras import backend as K
from tensorflow.keras.utils import to_categorical
from tensorflow.keras import applications # Modelos 
import numpy as np
import matplotlib.pyplot as plt
from scipy import interp
from itertools import cycle
import itertools
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
import pandas as pd
import shutil

ruta_dataset_entrenamiento = '/content/gdrive/My Drive/facial_expressions-master/entrenamiento'
ruta_dataset_prueba = '/content/gdrive/My Drive/facial_expressions-master/prueba'
ruta_dataset_validacion = '/content/gdrive/My Drive/facial_expressions-master/validacion'
num_classes = 7

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(ruta_dataset_entrenamiento,target_size=(80,80),color_mode='rgb',batch_size=32,class_mode='categorical',shuffle=True)
test_generator = test_datagen.flow_from_directory(ruta_dataset_prueba,target_size=(80,80),color_mode='rgb',batch_size=1,class_mode='categorical',shuffle=False)
validation_generator = validation_datagen.flow_from_directory(ruta_dataset_validacion,target_size=(80,80),color_mode='rgb',batch_size=32,class_mode='categorical',shuffle=True)

modelo = Sequential()
modelo.add(Conv2D(32, kernel_size=(3, 3),padding='same', activation='relu',input_shape=(80, 80, 3)))
modelo.add(MaxPooling2D(pool_size=(2, 2)))
modelo.add(Conv2D(64, kernel_size=(2, 2),padding='same', activation='relu'))
modelo.add(MaxPooling2D(pool_size=(2, 2)))
modelo.add(Flatten())
modelo.add(Dense(256, activation='relu'))
modelo.add(Dropout(0.5))
modelo.add(Dense(7, activation='softmax'))
modelo.summary()
modelo.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""***MODELO***"""

step_size_train=train_generator.n/train_generator.batch_size
step_size_validation=validation_generator.n/validation_generator.batch_size
modelo.fit_generator(train_generator,steps_per_epoch=step_size_train,validation_data = validation_generator,validation_steps = step_size_validation,epochs=40)

dir='/content/gdrive/My Drive/facial_expressions-master/'

if not os.path.exists(dir):
  os.mkdir(dir)
modelo.save('/content/gdrive/My Drive/facial_expressions-master/modelo3.h5')
modelo.save_weights('/content/gdrive/My Drive/facial_expressions-master/pesos3.h5')

model_loaded = load_model('/content/gdrive/My Drive/facial_expressions-master/modelo3.h5')

step_size_test=test_generator.n/test_generator.batch_size
result_evaluate =  model_loaded.evaluate_generator(test_generator,step_size_test,verbose=1)

y_pred_prob =  model_loaded.predict_generator(test_generator, steps= step_size_test)
y_pred_classes = np.argmax(y_pred_prob, axis=1)
test_labels_one_hot = to_categorical(test_generator.classes)

print(test_generator.classes)
print(y_pred_classes)

"""***EVALUACION***"""

accuracy = accuracy_score(test_generator.classes, y_pred_classes)
print('Accuracy: %f' % accuracy)
precision = precision_score(test_generator.classes, y_pred_classes, average = 'macro')
print('Precision:', precision)
recall = recall_score(test_generator.classes, y_pred_classes, average = 'macro')
print('Recall: %f' % recall)
f1 = f1_score(test_generator.classes, y_pred_classes, average = 'macro')
print('F1 score: %f' % f1)
kappa = cohen_kappa_score(test_generator.classes, y_pred_classes)
print('Cohens kappa: %f' % kappa)
matrix = confusion_matrix(test_generator.classes, y_pred_classes)
print(matrix)

"""***OTROS MODELOS***

**MobileNet**
"""

mobilenet=applications.mobilenet.MobileNet()

net= Sequential()
for capa in mobilenet.layers:  #hacemos una copia del modelo, para modificarlo
  net.add(capa)
net.pop()          #Eliminamos prediccion para clases predeterminadas 

for layer in net.layers:  #Evitamos que las capas vuelvan a entrenar
  layer.trainable=False
net.add(Dense(7,activation='softmax'))

net.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
net.summary()

step_size_train=train_generator.n/train_generator.batch_size
step_size_validation=validation_generator.n/validation_generator.batch_size
net.fit_generator(train_generator,steps_per_epoch=step_size_train,validation_data = validation_generator,validation_steps = step_size_validation,epochs=32)

dir='/content/gdrive/My Drive/Modelos'

if not os.path.exists(dir):
  os.mkdir(dir)
net.save('/content/gdrive/My Drive/Modelos/modelo-Net.h5')
net.save_weights('/content/gdrive/My Drive/Modelos/peso-Net.h5')

"""**VGG16**"""

modelovgg16=applications.vgg16.VGG16() #Importamos el modelo

vgg16= Sequential()
for capa in modelovgg16.layers:  #hacemos una copia del modelo, para modificarlo
  vgg16.add(capa)
vgg16.pop()          #Eliminamos prediccion para clases predeterminadas 

for layer in vgg16.layers:  #Evitamos que las capas vuelvan a entrenar
  layer.trainable=False
vgg16.add(Dense(7,activation='softmax'))

vgg16.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
vgg16.summary()

step_size_train=train_generator.n/train_generator.batch_size
step_size_validation=validation_generator.n/validation_generator.batch_size
vgg16.fit_generator(train_generator,steps_per_epoch=step_size_train,validation_data = validation_generator,validation_steps = step_size_validation,epochs=32)

dir='/content/gdrive/My Drive/Modelos'

if not os.path.exists(dir):
  os.mkdir(dir)
vgg16.save('/content/gdrive/My Drive/Modelos/modelo-Vgg16.h5')
vgg16.save_weights('/content/gdrive/My Drive/Modelos/peso-Vgg16.h5')

"""**VGG19**"""

modelovgg19=applications.vgg19.VGG19()

vgg19= Sequential()
for capa in modelovgg19.layers:  #hacemos una copia del modelo, para modificarlo
  vgg19.add(capa)
vgg19.pop()          #Eliminamos prediccion para clases predeterminadas 

for layer in vgg19.layers:  #Evitamos que las capas vuelvan a entrenar
  layer.trainable=False
vgg19.add(Dense(7,activation='softmax'))

vgg19.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
vgg19.summary()

step_size_train=train_generator.n/train_generator.batch_size
step_size_validation=validation_generator.n/validation_generator.batch_size
vgg19.fit_generator(train_generator,steps_per_epoch=step_size_train,validation_data = validation_generator,validation_steps = step_size_validation,epochs=32)

dir='/content/gdrive/My Drive/Modelos'

if not os.path.exists(dir):
  os.mkdir(dir)
vgg19.save('/content/gdrive/My Drive/Modelos/modelo-Vgg19.h5')
vgg19.save_weights('/content/gdrive/My Drive/Modelos/peso-Vgg19.h5')

"""***Comparacion de los modelos***"""

def evaluacion(model_loaded):
  step_size_test=test_generator.n/test_generator.batch_size
  result_evaluate =  model_loaded.evaluate_generator(test_generator,step_size_test,verbose=1)
  y_pred_prob =  model_loaded.predict_generator(test_generator, steps= step_size_test)
  y_pred_classes = np.argmax(y_pred_prob, axis=1)
  test_labels_one_hot = to_categorical(test_generator.classes)
  accuracy = accuracy_score(test_generator.classes, y_pred_classes)
  print('Accuracy: %f' % accuracy)
  precision = precision_score(test_generator.classes, y_pred_classes, average = 'macro')
  print('Precision:', precision)
  recall = recall_score(test_generator.classes, y_pred_classes, average = 'macro')
  print('Recall: %f' % recall)
  f1 = f1_score(test_generator.classes, y_pred_classes, average = 'macro')
  print('F1 score: %f' % f1)
  kappa = cohen_kappa_score(test_generator.classes, y_pred_classes)
  print('Cohens kappa: %f' % kappa)
  matrix = confusion_matrix(test_generator.classes, y_pred_classes)
  print(matrix)

model_loaded = load_model('/content/gdrive/My Drive/Modelos/modelo-Net.h5')
print("MODELO MOBILENET")
evaluacion(model_loaded)
model_loaded = load_model('/content/gdrive/My Drive/Modelos/modelo-Vgg16.h5')
print("MODELO VGG16")
evaluacion(model_loaded)
model_loaded = load_model('/content/gdrive/My Drive/Modelos/modelo-Vgg19.h5')
print("MODELO VGG19")
evaluacion(model_loaded)

model_loaded = load_model('/content/gdrive/My Drive/facial_expressions-master/modelo3.h5')
print("NUESTRO MODELO")
evaluacion(model_loaded)

"""***IPYTHON***"""

pip install mtcnn

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='photo.jpg', quality=0.8):
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

from IPython.display import Image
try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  display(Image(filename))
except Exception as err:
 
  print(str(err))



from google.colab import drive
drive.mount('/content/gdrive')

import numpy as np
from keras.preprocessing.image import load_img, img_to_array
from keras.models import load_model

longitud, altura = 80,80
modelo = '/content/gdrive/My Drive/facial_expressions-master/modelo3.h5'
pesos_modelo = '/content/gdrive/My Drive/facial_expressions-master/pesos3.h5'
cnn = load_model(modelo)
cnn.load_weights(pesos_modelo)

def predict(file):
  x = load_img(file, target_size=(longitud, altura))
  x = img_to_array(x)
  x = np.expand_dims(x, axis=0)
  array = cnn.predict(x)
  result = array[0]
  answer = np.argmax(result)
  if answer == 0:
    print("pred: Anger")
  elif answer == 1:
    print("pred: Disgust")
  elif answer == 2:
    print("pred: Fear")
  if answer == 3:
    print("pred: Happiness")
  elif answer == 4:
    print("pred: Sadness")
  elif answer == 5:
    print("pred: Neutral")
  elif answer == 6:
    print("pred: Surprise")

  return answer
predict(filename)